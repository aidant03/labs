{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "# Hedonic Pricing\n",
    "\n",
    "We often try to predict the price of an asset from its observable characteristics. This is generally called **hedonic pricing**: How do the unit's characteristics determine its market price?\n",
    "\n",
    "In the lab folder, there are three options: housing prices in pierce_county_house_sales.csv, car prices in cars_hw.csv, and airbnb rental prices in airbnb_hw.csv. If you know of another suitable dataset, please feel free to use that one.\n",
    "\n",
    "1. Clean the data and perform some EDA and visualization to get to know the data set.\n",
    "2. Transform your variables --- particularly categorical ones --- for use in your regression analysis.\n",
    "3. Implement an ~80/~20 train-test split. Put the test data aside.\n",
    "4. Build some simple linear models that include no transformations or interactions. Fit them, and determine their RMSE and $R^2$ on the both the training and test sets. Which of your models does the best?\n",
    "5. Include transformations and interactions, and build a more complex model that reflects your ideas about how the features of the asset determine its value. Determine its RMSE and $R^2$ on the training and test sets. How does the more complex model your build compare to the simpler ones?\n",
    "6. Summarize your results from 1 to 5. Have you learned anything about overfitting and underfitting, or model selection?\n",
    "7. If you have time, use the sklearn.linear_model.Lasso to regularize your model and select the most predictive features. Which does it select? What are the RMSE and $R^2$? We'll cover the Lasso later in detail in class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30478, 13) \n",
      "\n",
      "Total missing:  0\n",
      "        variable  coefficient\n",
      "0       Brooklyn    32.936408\n",
      "1      Manhattan    99.813274\n",
      "2         Queens     4.282124\n",
      "3  Staten Island    77.188159\n",
      "Rsq:  0.030673261290627973\n",
      "RMSE:  226.8281340018276\n",
      "Rsq:  0.037963986587503995\n",
      "RMSE:  185.12846105729506\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./airbnb_hw.csv', low_memory=False)\n",
    "print( df.shape, '\\n')\n",
    "df.head()\n",
    "\n",
    "df['Price'] = df['Price'].str.replace(',','') \n",
    "df['Price'] = pd.to_numeric(df['Price'],errors='coerce') \n",
    "print('Total missing: ', sum(df['Price'].isnull()))\n",
    "\n",
    "X = pd.get_dummies(df['Neighbourhood '], dtype='int', drop_first = True)\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['Price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=100)\n",
    "\n",
    "reg = linear_model.LinearRegression(fit_intercept = True).fit(X_train, y_train)\n",
    "\n",
    "results = pd.DataFrame({'variable':reg.feature_names_in_, 'coefficient': reg.coef_}) # Regression coefficients\n",
    "print(results)\n",
    "\n",
    "y_hat = reg.predict(X_test)\n",
    "print('Rsq: ', reg.score(X_test,y_test)) # R2\n",
    "rmse = np.sqrt( np.mean( (y_test - y_hat)**2 ))\n",
    "print('RMSE: ', rmse) # R2\n",
    "\n",
    "y_hat = reg.predict(X_train)\n",
    "print('Rsq: ', reg.score(X_train,y_train)) # R2\n",
    "rmse = np.sqrt( np.mean( (y_train - y_hat)**2 ))\n",
    "print('RMSE: ', rmse) # R2\n",
    "\n",
    "#it seems like the train and test models are somewhat similar. Although, the training model has a slightly lower RMSE which means the values are a bit tighter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        variable  coefficient\n",
      "0       Brooklyn     0.372101\n",
      "1      Manhattan     0.771994\n",
      "2         Queens     0.158732\n",
      "3  Staten Island     0.233826\n",
      "Rsq:  0.13302680647143117\n",
      "RMSE:  0.5922451412721083\n",
      "Rsq:  0.13586951944201642\n",
      "RMSE:  0.5815317317008505\n"
     ]
    }
   ],
   "source": [
    "y = np.log(df['Price'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=100)\n",
    "\n",
    "reg = linear_model.LinearRegression(fit_intercept = True).fit(X_train, y_train)\n",
    "\n",
    "results = pd.DataFrame({'variable':reg.feature_names_in_, 'coefficient': reg.coef_}) # Regression coefficients\n",
    "print(results)\n",
    "\n",
    "y_hat = reg.predict(X_test)\n",
    "print('Rsq: ', reg.score(X_test,y_test)) # R2\n",
    "rmse = np.sqrt( np.mean( (y_test - y_hat)**2 ))\n",
    "print('RMSE: ', rmse) # R2\n",
    "\n",
    "y_hat = reg.predict(X_train)\n",
    "print('Rsq: ', reg.score(X_train,y_train)) # R2\n",
    "rmse = np.sqrt( np.mean( (y_train - y_hat)**2 ))\n",
    "print('RMSE: ', rmse) # R2\n",
    "\n",
    "#for this one, i did the log of price. The regression is similar it seems from training to test. Since it's the log, it's also more condensed than the full regression previously done.\n",
    "#I think overall I learned that while I didn't try other trials on different ratios of test sizes, there can still be differences when running multiple kinds of regressions.\n",
    "#Although some didn't look the way I expected for example the log coefficients and R2 and RMSE, there is still information to be gleaned from each one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
